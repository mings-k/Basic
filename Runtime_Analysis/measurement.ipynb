{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MACs 측정하기\n",
    "\n",
    "- MACs를 측정하기 위해 thop library를 사용했습니다. \n",
    "\n",
    "- [출처] https://pypi.org/project/thop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트를 위한 모델 사용 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)        \n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)     \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))   \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting calflops\n",
      "  Downloading calflops-0.3.2-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\users\\islab\\.conda\\envs\\mings\\lib\\site-packages (from calflops) (1.13.1)\n",
      "Collecting huggingface-hub>=0.16.4\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     -------------------------------------- 268.8/268.8 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting calflops\n",
      "  Downloading calflops-0.3.1-py3-none-any.whl (29 kB)\n",
      "  Downloading calflops-0.3.0-py3-none-any.whl (29 kB)\n",
      "  Downloading calflops-0.2.9-py3-none-any.whl (30 kB)\n",
      "  Downloading calflops-0.2.8-py3-none-any.whl (30 kB)\n",
      "  Downloading calflops-0.2.7-py3-none-any.whl (30 kB)\n",
      "  Downloading calflops-0.2.6-py3-none-any.whl (30 kB)\n",
      "  Downloading calflops-0.2.5-py3-none-any.whl (29 kB)\n",
      "  Downloading calflops-0.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\islab\\.conda\\envs\\mings\\lib\\site-packages (from torch>=1.1.0->calflops) (4.7.1)\n",
      "Installing collected packages: calflops\n",
      "Successfully installed calflops-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "MACs: 27336291840.0\n",
      "Params: 11173962.0\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "model = ResNet(ResidualBlock)\n",
    "input = torch.randn(1, 3, 224, 224)\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "\n",
    "print(f\"MACs: {macs}\")\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLOPs & MACs 측정하기\n",
    "\n",
    "- FLOPs를 측정하기 위해 calflops library를 사용했습니다. \n",
    "\n",
    "- [출처] https://github.com/MrYxJ/calculate-flops.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchscan\n",
      "  Downloading torchscan-0.1.2-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.5.0 in c:\\users\\islab\\.conda\\envs\\mings\\lib\\site-packages (from torchscan) (1.13.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\islab\\.conda\\envs\\mings\\lib\\site-packages (from torch<2.0.0,>=1.5.0->torchscan) (4.7.1)\n",
      "Installing collected packages: torchscan\n",
      "Successfully installed torchscan-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install calflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  11.17 M \n",
      "fwd MACs:                                                               27.2155 GMACs\n",
      "fwd FLOPs:                                                              54.5188 GFLOPS\n",
      "fwd+bwd MACs:                                                           81.6464 GMACs\n",
      "fwd+bwd FLOPs:                                                          163.556 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "ResNet(\n",
      "  11.17 M = 100% Params, 27.22 GMACs = 100% MACs, 54.52 GFLOPS = 49.9194% FLOPs\n",
      "  (conv1): Sequential(\n",
      "    1.86 K = 0.0166% Params, 86.7 MMACs = 0.3186% MACs, 183.04 MFLOPS = 0.159% FLOPs\n",
      "    (0): Conv2d(1.73 K = 0.0155% Params, 86.7 MMACs = 0.3186% MACs, 173.41 MFLOPS = 0.159% FLOPs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128 = 0.0011% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    147.97 K = 1.3242% Params, 7.4 GMACs = 27.1858% MACs, 14.84 GFLOPS = 13.571% FLOPs\n",
      "    (0): ResidualBlock(\n",
      "      73.98 K = 0.6621% Params, 3.7 GMACs = 13.5929% MACs, 7.42 GFLOPS = 6.7855% FLOPs\n",
      "      (left): Sequential(\n",
      "        73.98 K = 0.6621% Params, 3.7 GMACs = 13.5929% MACs, 7.41 GFLOPS = 6.7855% FLOPs\n",
      "        (0): Conv2d(36.86 K = 0.3299% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128 = 0.0011% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(36.86 K = 0.3299% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128 = 0.0011% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      73.98 K = 0.6621% Params, 3.7 GMACs = 13.5929% MACs, 7.42 GFLOPS = 6.7855% FLOPs\n",
      "      (left): Sequential(\n",
      "        73.98 K = 0.6621% Params, 3.7 GMACs = 13.5929% MACs, 7.41 GFLOPS = 6.7855% FLOPs\n",
      "        (0): Conv2d(36.86 K = 0.3299% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128 = 0.0011% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(36.86 K = 0.3299% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128 = 0.0011% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    525.57 K = 4.7035% Params, 6.58 GMACs = 24.1652% MACs, 13.18 GFLOPS = 12.0631% FLOPs\n",
      "    (0): ResidualBlock(\n",
      "      230.14 K = 2.0596% Params, 2.88 GMACs = 10.5723% MACs, 5.77 GFLOPS = 5.2776% FLOPs\n",
      "      (left): Sequential(\n",
      "        221.7 K = 1.984% Params, 2.77 GMACs = 10.1947% MACs, 5.56 GFLOPS = 5.0891% FLOPs\n",
      "        (0): Conv2d(73.73 K = 0.6598% Params, 924.84 MMACs = 3.3982% MACs, 1.85 GFLOPS = 1.6964% FLOPs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256 = 0.0023% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.61 MFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(147.46 K = 1.3196% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256 = 0.0023% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        8.45 K = 0.0756% Params, 102.76 MMACs = 0.3776% MACs, 208.73 MFLOPS = 0.1885% FLOPs\n",
      "        (0): Conv2d(8.19 K = 0.0733% Params, 102.76 MMACs = 0.3776% MACs, 205.52 MFLOPS = 0.1885% FLOPs, 64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256 = 0.0023% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      295.42 K = 2.6439% Params, 3.7 GMACs = 13.5929% MACs, 7.41 GFLOPS = 6.7855% FLOPs\n",
      "      (left): Sequential(\n",
      "        295.42 K = 2.6439% Params, 3.7 GMACs = 13.5929% MACs, 7.41 GFLOPS = 6.7855% FLOPs\n",
      "        (0): Conv2d(147.46 K = 1.3196% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256 = 0.0023% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.61 MFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(147.46 K = 1.3196% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256 = 0.0023% Params, 0 MACs = 0% MACs, 3.21 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    2.1 M = 18.7911% Params, 6.58 GMACs = 24.1652% MACs, 13.16 GFLOPS = 12.0631% FLOPs\n",
      "    (0): ResidualBlock(\n",
      "      919.04 K = 8.2248% Params, 2.88 GMACs = 10.5723% MACs, 5.76 GFLOPS = 5.2776% FLOPs\n",
      "      (left): Sequential(\n",
      "        885.76 K = 7.927% Params, 2.77 GMACs = 10.1947% MACs, 5.55 GFLOPS = 5.0891% FLOPs\n",
      "        (0): Conv2d(294.91 K = 2.6393% Params, 924.84 MMACs = 3.3982% MACs, 1.85 GFLOPS = 1.6964% FLOPs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512 = 0.0046% Params, 0 MACs = 0% MACs, 1.61 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 802.82 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(589.82 K = 5.2786% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512 = 0.0046% Params, 0 MACs = 0% MACs, 1.61 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        33.28 K = 0.2978% Params, 102.76 MMACs = 0.3776% MACs, 207.13 MFLOPS = 0.1885% FLOPs\n",
      "        (0): Conv2d(32.77 K = 0.2933% Params, 102.76 MMACs = 0.3776% MACs, 205.52 MFLOPS = 0.1885% FLOPs, 128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512 = 0.0046% Params, 0 MACs = 0% MACs, 1.61 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      1.18 M = 10.5663% Params, 3.7 GMACs = 13.5929% MACs, 7.4 GFLOPS = 6.7855% FLOPs\n",
      "      (left): Sequential(\n",
      "        1.18 M = 10.5663% Params, 3.7 GMACs = 13.5929% MACs, 7.4 GFLOPS = 6.7855% FLOPs\n",
      "        (0): Conv2d(589.82 K = 5.2786% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512 = 0.0046% Params, 0 MACs = 0% MACs, 1.61 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 802.82 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(589.82 K = 5.2786% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512 = 0.0046% Params, 0 MACs = 0% MACs, 1.61 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    8.39 M = 75.1186% Params, 6.58 GMACs = 24.1652% MACs, 13.16 GFLOPS = 12.0631% FLOPs\n",
      "    (0): ResidualBlock(\n",
      "      3.67 M = 32.8718% Params, 2.88 GMACs = 10.5723% MACs, 5.76 GFLOPS = 5.2776% FLOPs\n",
      "      (left): Sequential(\n",
      "        3.54 M = 31.6897% Params, 2.77 GMACs = 10.1947% MACs, 5.55 GFLOPS = 5.0891% FLOPs\n",
      "        (0): Conv2d(1.18 M = 10.5571% Params, 924.84 MMACs = 3.3982% MACs, 1.85 GFLOPS = 1.6964% FLOPs, 256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1.02 K = 0.0092% Params, 0 MACs = 0% MACs, 802.82 KFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 401.41 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(2.36 M = 21.1142% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(1.02 K = 0.0092% Params, 0 MACs = 0% MACs, 802.82 KFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        132.1 K = 1.1822% Params, 102.76 MMACs = 0.3776% MACs, 206.32 MFLOPS = 0.1885% FLOPs\n",
      "        (0): Conv2d(131.07 K = 1.173% Params, 102.76 MMACs = 0.3776% MACs, 205.52 MFLOPS = 0.1885% FLOPs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1.02 K = 0.0092% Params, 0 MACs = 0% MACs, 802.82 KFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      4.72 M = 42.2468% Params, 3.7 GMACs = 13.5929% MACs, 7.4 GFLOPS = 6.7855% FLOPs\n",
      "      (left): Sequential(\n",
      "        4.72 M = 42.2468% Params, 3.7 GMACs = 13.5929% MACs, 7.4 GFLOPS = 6.7855% FLOPs\n",
      "        (0): Conv2d(2.36 M = 21.1142% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1.02 K = 0.0092% Params, 0 MACs = 0% MACs, 802.82 KFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 401.41 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(2.36 M = 21.1142% Params, 1.85 GMACs = 6.7965% MACs, 3.7 GFLOPS = 3.3928% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(1.02 K = 0.0092% Params, 0 MACs = 0% MACs, 802.82 KFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 401.41 KFLOPS = 0% FLOPs, output_size=(1, 1))\n",
      "  (fc): Linear(5.13 K = 0.0459% Params, 5.12 KMACs = 0% MACs, 10.24 KFLOPS = 0% FLOPs, in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ResNet FLOPs:54.5188 GFLOPS   MACs:27.2155 GMACs   Params:11.174 M \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from calflops import calculate_flops\n",
    "\n",
    "model = ResNet(ResidualBlock)\n",
    "input_shape = (1, 3, 224, 224)\n",
    "\n",
    "flops, macs, params = calculate_flops(model=model, \n",
    "                                      input_shape=input_shape,\n",
    "                                      output_as_string=True,\n",
    "                                      output_precision=4)\n",
    "print(\"ResNet FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
